{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This project implements a sentiment analysis pipeline using the Hugging Face transformers and datasets libraries, fine-tuning a pre-trained BERT model (bert-base-uncased) on the IMDb movie reviews dataset. The pipeline begins with data loading and preprocessing, where the dataset is either fetched via load_dataset(). The text data is tokenized using the BertTokenizer, ensuring truncation and padding are applied to fit BERT’s input size. We fine-tune TFBertForSequenceClassification (a TensorFlow-compatible version of BERT) on the IMDb dataset using model.fit(). The optimizer is created using Hugging Face’s create_optimizer utility, which schedules learning rate decay. The model is trained for two epochs and evaluated using accuracy and loss metrics on a validation split. After training, the model is saved and reused for inference on sample text using a custom predict_sentiment function. This pipeline leverages transfer learning to minimize training time and achieve high performance on a binary classification task."
      ],
      "metadata": {
        "id": "7laie5IejHxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5PV-Cpe30Pg",
        "outputId": "30d9c627-1762-4fd4-f00d-7fbfc0760349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (0.21.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U datasets huggingface_hub fsspec # using this because there were some errors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "npLImkGy6jDD",
        "outputId": "04b55d4a-3105-4eb7-cd3c-9feae21acc9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (2025.3.2)\n",
            "Collecting fsspec\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.5)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.4/515.4 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fsspec, huggingface_hub, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.33.1\n",
            "    Uninstalling huggingface-hub-0.33.1:\n",
            "      Successfully uninstalled huggingface-hub-0.33.1\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 huggingface_hub-0.33.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "datasets",
                  "fsspec"
                ]
              },
              "id": "ef56a0d30ca54f5ba4de0de3d68f1c74"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorWithPadding\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "mV9kTLvq6_di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDb dataset\n",
        "dataset = load_dataset(\"imdb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "73471db51cd84d139620627145df5871",
            "107853d06cfc4acdb733a02c86971323",
            "e7612e71ccb04fd9b49fda1bae6ad635",
            "e62d10695439415a80d244225cb98af7",
            "9e1e2305eadd4a918dec5024a97e9ec6",
            "f14700f6c013429ab8e5a56a5ae41e3d",
            "11972274aaca4ee4ae1db3bfed12932f",
            "a9df6ec4a7584af7b1377645a91e088c",
            "98bb2aea489f4ad6999e898bad9f6fbc",
            "dca28d674f67458bbcd8b072897248ae",
            "6c4cc2f84d0e42438ad7bc278ac08858",
            "4ecbb2be74bb4a36b029008face294db",
            "35a25ac17189400bb4a284aa333c615b",
            "9752be5edb2541ddb24bbf5c9e014cc3",
            "bfb71543e848405bb6b0cd9557c81d61",
            "cab531ccbe4d450abdf54a35fba6a24c",
            "76ee9b1997854cac91513d0bc0aa8fb1",
            "1bbe0e53866241c092e1bfe7b2611b64",
            "ffb8a0062ba8477ea9ab7f956ae92435",
            "c6f1aa11d16542099ae2046755af71cb",
            "1ed3a05628d046d09354635b66981e9c",
            "d80f0390047940a9b9b6ab9bfe02b59f",
            "2ffe17a14fa74e1e82b45ae539908732",
            "a65a7b39b1ec4f1baa67c48c973b53e0",
            "5f1c5589068d4e3abf699053323824da",
            "1e403a23616c4476a9249ab4ce237011",
            "38e30a285afc4bab9070da80e111fec4",
            "6a57b8940f6d44df82cdc5b15078de07",
            "defabcff8cfd42dda60cbfd24029ed71",
            "e8c24ec68418470092988c3723100f71",
            "318e64100fe34f99becae263c3057cca",
            "a095b6552b2f468996d01c2ddad82dab",
            "b750e1fc6f104e5e99f7399962b5fc9d",
            "5f262bd7183846e594203f5ded6a7401",
            "70906405f87845329167178771a4204f",
            "96243bcf06aa40288b61de50e053db67",
            "219d170c5f0e4460bda6fb6be132b66b",
            "fc86ac4521254799a13854ba0cfa004f",
            "3a32f34542644dfeab0135603915b786",
            "e72aace7bb5e4b7aad4f2f66a853f1d5",
            "c774a03a4a184c1989b21448c9730cb2",
            "d104424670f04144b61bca0f3ebb66cc",
            "3cf46a749d3447cab00b93bc18eabaab",
            "cfe16f6ef38249769477ab522fa136ae",
            "3f1d26ba23ac41ad840ec6d1dfda6417",
            "7f6bfb64538e432798d26fd3b4bce734",
            "4893af6c673d4e1a881118031ce078a1",
            "cd3b8dd0dd644c8b8961e9afd078619a",
            "738631401a0c4adaae0f4b05ab2e364c",
            "df2cd6a5e4294a6bae1fdd917cf9d57e",
            "76261908cd914dfa9e73f8c78946f3c3",
            "296f0a1b70314613be674090be983363",
            "1c55d6e9b32b4904afca816b0c482fca",
            "482c4a35bc974c568746234f86a6396f",
            "8e3bf26180054e78a610b4a9ed7099c4",
            "363cfb972fdb4fb887ab49a81d65e846",
            "67363fc39dac4101866d8494f088f9ed",
            "dbe36cebc35346e4a58bfa38d06f52e5",
            "47685da3d8954657a96d58dfb7c49a19",
            "ce88ea1e67d4488a9881ea9e9f5939ef",
            "933875002a69419d806754de4eacdb58",
            "cc1471f21cf14f24900045e16d7be9cd",
            "fcc3ab2d7daa45d28f9162320d8be402",
            "55894bcaabec4d77b83b99ba8e0f8295",
            "6cf454094484498a9f8ce88c1d3b351d",
            "e1462234aefc47e090b2349ab56f8f9b",
            "0743d5e7b5984ce9bf1afa2ced9f37a4",
            "2696cb13e9fc4bea9a6b86b04120374d",
            "8cb3b61f4dd243578ef9103721c81106",
            "b5196f38d96945b6b95fad4a54b27cbd",
            "788b64b8e15441cca3f85d773f308079",
            "d582d4afee6b4dbfa39db17d9cce0f63",
            "c07904ce4e644526af28f41cb7fa756d",
            "a3dc496da5ed453090ba4dfc95b4bc86",
            "2026e8f4d51b432d898ac1d7de69012d",
            "a6739d77b3fa445a90819e7de8a5e0ab",
            "7a571c9e075c465eb851ab263879acd0"
          ]
        },
        "id": "271Iwrj65W2P",
        "outputId": "8d16e627-963c-4d6e-984b-1d960119f624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73471db51cd84d139620627145df5871"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ecbb2be74bb4a36b029008face294db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ffe17a14fa74e1e82b45ae539908732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsupervised-00000-of-00001.parquet:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f262bd7183846e594203f5ded6a7401"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f1d26ba23ac41ad840ec6d1dfda6417"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "363cfb972fdb4fb887ab49a81d65e846"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0743d5e7b5984ce9bf1afa2ced9f37a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ee78fec2017243449943cb2c209ab516",
            "b0534a77fc60408184c5a6e751e39e5a",
            "9eb04ccef8e8473581502f79598345f3",
            "819ccb5db69d4f67ac7b7ae99bc4770e",
            "a912440418714d9ba2aca7f1838a7d4b",
            "1b242a7bbf3042f9b05f4614e4410447",
            "ca76290795ab4d7b94f40a6637a55a7c",
            "c9bdf5fab2c74edc8f8a6a2e7b3e51cf",
            "48047d1ef26047609ffddf60b5cb9682",
            "a672818428374c4cae3b580d7249e781",
            "d3a99077c3b04fcabff51b8684ce115f",
            "b0b04d699a4c4f34a562bc970f881ab1",
            "e7d073346f1e4224baacbc530cce93d5",
            "792c2d70425d4acd96cb79a19bf8c1fa",
            "f5b3460c9fed44d79f49cc2e16c2972f",
            "811b095384454290a0cefee4195793d7",
            "6fec28b53146495896547dcd639143a1",
            "e5f641eb395e4bd5a257222f061fd5a4",
            "6a49bd26353b4cabad2e921919ca4161",
            "dbc3724fddfa49ec852bdac5f618ca5d",
            "9a5e418aa183461fb3c43bdb5e8462b4",
            "96fb70e6fc7c4a04a554d87111d0fbfa",
            "73e018f5c39b4909a3b22b7c24abce34",
            "190ca57d1f4c48938c7e84985147f464",
            "e7e29893701c4712934857d055b13d4a",
            "5da15d209e0044ff997b2108fbc4feef",
            "9b0e9dfe17374fb7b45b9c02a5b6e439",
            "31555cb37b8c4667aa81d13316b6654b",
            "845f4596648c4e57a74f24f2d770fd9f",
            "562bfa01a8e24bafba031c38a8662585",
            "184269b1f73e45eab1fb8da70f749007",
            "811f76075c0142a08253826e6fb3c813",
            "8cc704ba13034fb58186ceefddf098d1",
            "acd580c31bad4842b5c6b3c7b3ce75b6",
            "5e9c74f023d64d3e93ee080cac6bcdeb",
            "5d292f8d500a49e6968e55e145e9388b",
            "3b24666feafc48789a4d09d57cb72013",
            "0cbb77809fe44c7da5abc8c1fcf5f8a3",
            "4eb72f76fc9d4ceb9bb3abfd73f2da3c",
            "c8c63e9f6a794c8ca03bd25dcf5c0b1d",
            "d6cfdd48eef743668489b9b3607f4e24",
            "d7207b2e8a704433abea49002d246181",
            "e49871814b114d849d9ca7d5eeeab69c",
            "659a22b668634e60a083c8d5dae1b762"
          ]
        },
        "id": "fbZLF7Dx5jvW",
        "outputId": "b0c473cf-742f-4db9-c817-d2f8e2063d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee78fec2017243449943cb2c209ab516"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0b04d699a4c4f34a562bc970f881ab1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73e018f5c39b4909a3b22b7c24abce34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acd580c31bad4842b5c6b3c7b3ce75b6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess dataset: Tokenize\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "rhPhXdYz7uSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "ba525a4a50ef47a9ac27510cf3eeb4ae",
            "e4df035bce8a4ca2a40d42c5c98d6e5c",
            "bbfb4d0c09b94885bcd8a57df6befcd1",
            "1cfa1c9430764de48e80e533047670c7",
            "92c41deae1cf4b79ada4b775a805dc43",
            "2228557b3eb2459489b82bbba2b7920c",
            "288f7a223d414a6593edf0530d26999e",
            "12e479e832d041b9acf2ab2c855ea7d2",
            "904fd4a6adce491fb86d2fd8d599466f",
            "1eb5db3c8d1b4c4faf8500b99e365b76",
            "025f7233c2c44e15873ba6a971a99baa",
            "570fd8dd03624af4b707e8e080626e42",
            "6c04b0cca05c4218b5b8f49112fda5ac",
            "8020d316253948d38e229d4b8ed5454c",
            "8860376d42be449093164d714aba0c96",
            "d1ad4c8b256749dbacc8c23f3d0d9787",
            "49cdfec4ca0a45b1b34ca4134e3dc686",
            "11a58ecdda184842a02e278deda4f2d7",
            "abc1a332ba15474489d9967058f74d19",
            "544f9bcbfaae4ee49213db39d21abaf3",
            "a4914ca45343410598bc8c687de40732",
            "806a1b10fb794315a2497ae2e55bbeed",
            "05ec2492ded14d5894af1f0f19bef0c8",
            "59b3f5c4d98b4dc5bea721c17975583d",
            "ec6c31504d4246d981038274fff61c5b",
            "cc557249c77a45c9ab7d1574c1bdc12b",
            "086fdc6a48724e72baa3cd29beeeda81",
            "5819e5026e2545a5ab275385f0d11dd9",
            "eafa674a750e42f9a70a3c540ad1ad3b",
            "5ab59f660cdf4c4d9424d90e88bf7109",
            "895e495a7f3342d0a9011937d3dafa19",
            "7e6f3e659ff841a3a3b2a9d0ee2ed426",
            "a33e0be653914459b395019b4818ef75"
          ]
        },
        "id": "xNfAZ0a_7wo5",
        "outputId": "219f2fb7-8dc3-4f47-e435-cf538f8d519d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba525a4a50ef47a9ac27510cf3eeb4ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "570fd8dd03624af4b707e8e080626e42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05ec2492ded14d5894af1f0f19bef0c8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test sets\n",
        "train_dataset = tokenized_datasets[\"train\"]\n",
        "test_dataset = tokenized_datasets[\"test\"]"
      ],
      "metadata": {
        "id": "Uxh50NtO7y8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model for binary classification\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "10e7968681384dab8bbbe7a34784c8b8",
            "e982a118ef6c4447a2fd4dd91f387cb3",
            "2e6d21a5e5314155b69ef8be6f7826a3",
            "a79764ebdb5147e19f4d280ff117e9c6",
            "dedebdf8bb544ffbb6701ef92f1b231c",
            "904b51b683ee4a28a890d7d68c1f5b65",
            "5d01e04da18e4df78b1a101fbefdf00b",
            "b1958a703c73441ca91183c8bd21c204",
            "6e7e1898905d48cdacddba2a5299bf73",
            "c356129665c14e5bbc19231efc3ede9c",
            "2217fad2c5894371b6a5ac487f009681"
          ]
        },
        "id": "z1tvfEKF-YYI",
        "outputId": "96894c51-7b1a-4eab-e863-fb7b4134f295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10e7968681384dab8bbbe7a34784c8b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data collator for dynamic padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "kWualrtS90UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute metrics\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "xuscvu4K94hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_total_limit=1,\n",
        "    report_to=[]\n",
        ")"
      ],
      "metadata": {
        "id": "aDBiA2qQ97PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset.shuffle(seed=42).select(range(2000)),  # subset for speed\n",
        "    eval_dataset=test_dataset.select(range(1000)),  # subset for speed\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIZQHCn99-0b",
        "outputId": "5baa940c-a78d-459d-d424-d0a811b39737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-20-35683949.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "B77wG1qpAhuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "0tRh3LXF-pJb",
        "outputId": "162069ca-080d-497e-80dc-1e688ff8f000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 07:28, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.385300</td>\n",
              "      <td>0.531316</td>\n",
              "      <td>0.812000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.389994</td>\n",
              "      <td>0.901000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.2449758805632591, metrics={'train_runtime': 449.0833, 'train_samples_per_second': 8.907, 'train_steps_per_second': 1.113, 'total_flos': 973938460296960.0, 'train_loss': 0.2449758805632591, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "metrics = trainer.evaluate()\n",
        "print(\"Evaluation metrics:\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "bgaeXEj1-r7k",
        "outputId": "585da564-a63f-40ef-daeb-1dfeba3aa392"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:28]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation metrics: {'eval_loss': 0.3899937868118286, 'eval_accuracy': 0.901, 'eval_f1': 0.0, 'eval_runtime': 28.6301, 'eval_samples_per_second': 34.928, 'eval_steps_per_second': 4.366, 'epoch': 2.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_path = \"./fine-tuned-bert-imdb\"\n",
        "trainer.save_model(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YpMbOPY-ueB",
        "outputId": "7da1a894-21b6-47fa-cfe0-3a4234217545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-bert-imdb/tokenizer_config.json',\n",
              " './fine-tuned-bert-imdb/special_tokens_map.json',\n",
              " './fine-tuned-bert-imdb/vocab.txt',\n",
              " './fine-tuned-bert-imdb/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference on new text\n",
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    # Move input tensors to the same device as the model\n",
        "    device = model.device\n",
        "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "    predicted_class = torch.argmax(logits).item()\n",
        "    return \"Positive\" if predicted_class == 1 else \"Negative\""
      ],
      "metadata": {
        "id": "hvNnYe6FCdGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example inference\n",
        "sample_text = \"I absolutely loved this movie. It was fantastic!\"\n",
        "print(\"Sample Text Prediction:\", predict_sentiment(sample_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HOu1JxICjuq",
        "outputId": "252786a9-38f7-47ad-d177-b4a725439eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Text Prediction: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xOlp2FcTFrS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}